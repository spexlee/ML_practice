{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4hggtyGJInMkbkiOZNWgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spexlee/ML_practice/blob/main/NCF_MovieLens_test_%EC%9D%B4%EC%98%88%EB%B9%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**서강대학교 정보통신대학원 데이터 사이언스 전공 이예빈**\n",
        "\n",
        "## NCF"
      ],
      "metadata": {
        "id": "Grb5xuPyMofJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpp6BY-VLRAd",
        "outputId": "e342ceea-f506-46b9-e51e-8dabdd6dfdf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-04 14:13:37--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  3.45MB/s    in 1.4s    \n",
            "\n",
            "2023-12-04 14:13:39 (3.45 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# 데이터셋 불러오기 (MovieLens 100K 데이터셋 사용)\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip ml-100k.zip\n",
        "\n",
        "# 데이터 로딩\n",
        "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user', 'item', 'rating', 'timestamp'])\n",
        "\n",
        "# 사용자 ID와 아이템 ID에 대해 레이블 인코딩\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "df['user'] = user_encoder.fit_transform(df['user'])\n",
        "df['item'] = item_encoder.fit_transform(df['item'])\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터로 분할\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 준비\n",
        "train_users, train_items, train_ratings = train_data['user'].values, train_data['item'].values, train_data['rating'].values\n",
        "test_users, test_items, test_ratings = test_data['user'].values, test_data['item'].values, test_data['rating'].values\n",
        "\n",
        "n_users = df['user'].nunique()\n",
        "n_items = df['item'].nunique()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 50\n",
        "\n",
        "# 입력 레이어\n",
        "user_input = Input(shape=(1,))\n",
        "item_input = Input(shape=(1,))\n",
        "\n",
        "# 임베딩 레이어\n",
        "user_embedding = Embedding(output_dim=embedding_size, input_dim=n_users)(user_input)\n",
        "item_embedding = Embedding(output_dim=embedding_size, input_dim=n_items)(item_input)\n",
        "\n",
        "# 벡터로 변환\n",
        "user_vector = Flatten()(user_embedding)\n",
        "item_vector = Flatten()(item_embedding)\n",
        "\n",
        "# 연결 및 밀집 레이어\n",
        "concat = Concatenate()([user_vector, item_vector])\n",
        "dense = Dense(128, activation='relu')(concat)\n",
        "output = Dense(1)(dense)\n",
        "\n",
        "# 모델 생성 및 컴파일\n",
        "model = Model(inputs=[user_input, item_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "z27Oia0nLSlu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping 콜백 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit([train_users, train_items], train_ratings, epochs=5, batch_size=128, verbose=1, validation_split=0.1, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjMVUASFLbag",
        "outputId": "8ed157ac-8c6f-45d5-e5ea-f11af10ca1b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "563/563 [==============================] - 9s 11ms/step - loss: 1.9578 - val_loss: 0.9492\n",
            "Epoch 2/5\n",
            "563/563 [==============================] - 5s 8ms/step - loss: 0.9131 - val_loss: 0.9356\n",
            "Epoch 3/5\n",
            "563/563 [==============================] - 5s 8ms/step - loss: 0.8884 - val_loss: 0.9259\n",
            "Epoch 4/5\n",
            "563/563 [==============================] - 6s 10ms/step - loss: 0.8768 - val_loss: 0.9089\n",
            "Epoch 5/5\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.8675 - val_loss: 0.8993\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6517c1be20>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([test_users, test_items], test_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx8BZGJULdK3",
        "outputId": "6986ee64-2491-43b2-a811-4a9479b463ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 2s 3ms/step - loss: 0.8829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.882853627204895"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLC3BlAKLprU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keras Functional API 사용"
      ],
      "metadata": {
        "id": "KxY9IO2DLsfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LgaCkadxMndm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "SF8o9N9bLyMK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# MovieLens 데이터셋 다운로드\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip\n",
        "\n",
        "# 데이터 로딩\n",
        "df = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "\n",
        "# 레이블 인코딩\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "df['userId'] = user_encoder.fit_transform(df['userId'])\n",
        "df['movieId'] = item_encoder.fit_transform(df['movieId'])\n",
        "\n",
        "# 데이터셋 분할\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# 입력 및 출력 데이터 준비\n",
        "train_users, train_movies, train_ratings = train_data['userId'].values, train_data['movieId'].values, train_data['rating'].values\n",
        "test_users, test_movies, test_ratings = test_data['userId'].values, test_data['movieId'].values, test_data['rating'].values\n",
        "\n",
        "n_users = df['userId'].nunique()\n",
        "n_movies = df['movieId'].nunique()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0VTsY82L8rO",
        "outputId": "21d35fd2-bb4e-4260-e9c0-7cdbb1b8571d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-04 14:23:48--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K   514KB/s    in 1.9s    \n",
            "\n",
            "2023-12-04 14:23:50 (514 KB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "\n",
        "embedding_size = 50\n",
        "\n",
        "# 입력 레이어\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "movie_input = Input(shape=(1,), name='movie_input')\n",
        "\n",
        "# 사용자 임베딩\n",
        "user_embedding = Embedding(output_dim=embedding_size, input_dim=n_users, input_length=1, name='user_embedding')(user_input)\n",
        "user_vector = Flatten(name='flatten_user')(user_embedding)\n",
        "\n",
        "# 영화 임베딩\n",
        "movie_embedding = Embedding(output_dim=embedding_size, input_dim=n_movies, input_length=1, name='movie_embedding')(movie_input)\n",
        "movie_vector = Flatten(name='flatten_movie')(movie_embedding)\n",
        "\n",
        "# 연결\n",
        "concat = Concatenate()([user_vector, movie_vector])\n",
        "\n",
        "# 밀집 레이어\n",
        "dense = Dense(128, activation='relu')(concat)\n",
        "output = Dense(1)(dense)\n",
        "\n",
        "# 모델 생성\n",
        "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# 컴파일\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "OU3052CeMJjC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([train_users, train_movies], train_ratings, epochs=5, batch_size=64, verbose=1)\n",
        "model.evaluate([test_users, test_movies], test_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAL4wdzvN4zl",
        "outputId": "e48d9779-5d8f-4123-8fea-0d37024e6120"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1261/1261 [==============================] - 13s 9ms/step - loss: 1.3108\n",
            "Epoch 2/5\n",
            "1261/1261 [==============================] - 12s 9ms/step - loss: 0.7197\n",
            "Epoch 3/5\n",
            "1261/1261 [==============================] - 12s 9ms/step - loss: 0.6726\n",
            "Epoch 4/5\n",
            "1261/1261 [==============================] - 11s 9ms/step - loss: 0.6427\n",
            "Epoch 5/5\n",
            "1261/1261 [==============================] - 11s 9ms/step - loss: 0.6133\n",
            "631/631 [==============================] - 1s 2ms/step - loss: 0.7685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7685096859931946"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TesnsorFlow Subclassing API"
      ],
      "metadata": {
        "id": "RPGELBirOud4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class NCFModel(tf.keras.Model):\n",
        "    def __init__(self, num_users, num_items, embedding_size, **kwargs):\n",
        "        super(NCFModel, self).__init__(**kwargs)\n",
        "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_size, input_length=1)\n",
        "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_size, input_length=1)\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_input, item_input = inputs\n",
        "        user_vector = tf.keras.layers.Flatten()(self.user_embedding(user_input))\n",
        "        item_vector = tf.keras.layers.Flatten()(self.item_embedding(item_input))\n",
        "        concat = self.concat([user_vector, item_vector])\n",
        "        x = self.dense1(concat)\n",
        "        output = self.dense2(x)\n",
        "        return output\n",
        "\n",
        "model = NCFModel(n_users, n_movies, 50)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "1RzVKaevO3On"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([train_users, train_movies], train_ratings, epochs=5, batch_size=64, verbose=1)\n",
        "model.evaluate([test_users, test_movies], test_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQdZKrbOO_dD",
        "outputId": "351f0ccd-34f7-4eec-af3f-bb8e4d067fd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1261/1261 [==============================] - 12s 9ms/step - loss: 1.2980\n",
            "Epoch 2/5\n",
            "1261/1261 [==============================] - 11s 9ms/step - loss: 0.7212\n",
            "Epoch 3/5\n",
            "1261/1261 [==============================] - 14s 11ms/step - loss: 0.6776\n",
            "Epoch 4/5\n",
            "1261/1261 [==============================] - 10s 8ms/step - loss: 0.6496\n",
            "Epoch 5/5\n",
            "1261/1261 [==============================] - 11s 9ms/step - loss: 0.6231\n",
            "631/631 [==============================] - 1s 2ms/step - loss: 0.7582\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7582489848136902"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rxddke0TPBr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}